## GaussianTalker 运行手册（当前工作状态）
vibe coding这一块
key可以直接找我要
### 当前已打通的流程
- 语音识别：上传 WAV 音频，识别文本保存到 `static/text/input.txt`。
- 大模型回复：根据识别文本生成回复，保存到 `static/text/output.txt`。
- 语音合成：将回复合成为语音，保存到 `static/audios/ai_response.wav`（使用本地 `pyttsx3`）。

### 近期关键改动
- `backend/chat_engine.py`
  - `get_ai_response(...)` 统一大模型调用逻辑，并对智谱密钥格式（`id.secret`）做了校验。
  - 安全兜底：若 LLM 调用失败，会将输入文本回显到 `output.txt`，保证后续 TTS 不中断。
- `app.py`
  - 关闭 Flask 自动重载（`use_reloader=False`），避免 Windows 上与 `pyttsx3/COM` 的重复重启问题。

### 启动步骤
1) 安装依赖（PowerShell）：
```bash
pip install -r requirements.txt
```
2) 配置环境变量（示例，仅在当前会话生效）：
```powershell
$env:ZHIPUAI_API_KEY = '你的id.你的secret'   # 调用智谱 API 所需
```
3) 启动服务：
```bash
python app.py
```
服务默认地址：http://127.0.0.1:5001

### 一次性对话接口
- 路径：`POST /chat/once`
- 表单字段：
  - `audio`：要识别的 WAV 文件
- 示例（PowerShell/curl）：
```bash
curl -F "audio=@static/audios/input.wav" http://127.0.0.1:5001/chat/once
```

### 生成的产物
- `static/text/input.txt`：识别得到的用户文本
- `static/text/output.txt`：大模型回复（或在失败时的输入回显）
- `static/audios/ai_response.wav`：将回复合成后的语音

### 环境变量
- `ZHIPUAI_API_KEY`：智谱 API Key，格式必须为 `id.secret`（不要加引号与空格）
- 模型可在代码中通过函数参数覆写（若未设置，使用默认值）

### 常见问题排查
- 报错 “invalid api_key, not enough values to unpack”：
  - 确认 `ZHIPUAI_API_KEY` 格式为 `id.secret`，无多余引号/空格。
  - 检查变量作用域：`Process`、`User`、`Machine` 是否有旧值覆盖。
- 未生成 `ai_response.wav`：
  - 查看控制台是否有 TTS 错误；检查音频设备可用性。
  - 确认 `output.txt` 是否存在；即使 LLM 失败也应看到输入回显。
- Windows 下服务频繁重启：
  - 确认 `app.py` 中已设置 `use_reloader=False`。

### 备注
- 默认从环境变量读取智谱密钥；若环境未配置，则使用函数入参作为后备。
- 整体链路具备韧性：识别 → LLM（或回显） → TTS，尽量保证全流程成功完成。


